{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybaseball import batting_stats_range\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hitting_dataset(date_ranges, predict_category, min_PA=None):\n",
    "    '''Build the dataset used for hitting predictions\n",
    "    \n",
    "    Args:\n",
    "      date_ranges (list of ranges)  List of date ranges to use\n",
    "        for the dataset.  There must be at least two ranges here.\n",
    "        One range that serve as the input data and the second that\n",
    "        will serve the predicted value.  If more then two ranges are\n",
    "        specified, the first n-1 will be used for the input data and\n",
    "        the last one will be for the predicted values.\n",
    "    \n",
    "      predict_category (str) The hitting category that we will predict.\n",
    "        The category name must be one of the columns returned by the\n",
    "        batting_stats_range() API.\n",
    "        \n",
    "      min_PA (int) If set, we will filter out rows that doesn't exceed\n",
    "        this minimum plate appearances\n",
    "        \n",
    "    Returns:\n",
    "      DataFrame: The dataset of k columns.  The first k-1 columns will be\n",
    "        the input values and the kth column is the predicted value.\n",
    "        \n",
    "    Examples:\n",
    "      df = build_hitting_dataset([['2016-01-01', '2016-12-31'],\n",
    "                                  ['2017-01-01', '2017-12-31']],\n",
    "                                 'HR')\n",
    "    '''\n",
    "    if len(date_ranges) <= 1:\n",
    "        raise RuntimeException(\"Must have at least 2 date ranges\")\n",
    "    input_ranges = date_ranges[:-1]\n",
    "    predict_range = date_ranges[-1]\n",
    "    input_data = None\n",
    "    \n",
    "    for i, dr in zip(range(len(input_ranges)), input_ranges):\n",
    "        data = transform_hitting(batting_stats_range(dr[0], dr[1]), min_PA=min_PA)\n",
    "        # We're going to join each of the input sets together, so we need \n",
    "        # to change the column name to avoid collision.\n",
    "        data.rename(lambda x: \"{}_P{}\".format(x, i) if x != \"Name\" else x,\n",
    "                    axis=1, inplace=True)\n",
    "        if input_data is None:\n",
    "            input_data = data\n",
    "        else:\n",
    "            input_data = pd.merge(input_data, data, on='Name')\n",
    "        \n",
    "    predict_full_data = transform_hitting(\n",
    "        batting_stats_range(predict_range[0], predict_range[1]), min_PA=min_PA)\n",
    "    predict_data = pd.DataFrame()\n",
    "    predict_data['Name'] = predict_full_data['Name']\n",
    "    predict_data[predict_category] = predict_full_data[predict_category]\n",
    "    return pd.merge(input_data, predict_data, on='Name')\n",
    "\n",
    "    \n",
    "def transform_hitting(df, min_PA=None):\n",
    "    '''Transform column values in a hitting dataset\n",
    "    \n",
    "    Args:\n",
    "      df (DataFrame) Hitting DataFrame to transform\n",
    "      minPA (int)  Filter out rows that don't match this minimum plate appearence\n",
    "      \n",
    "    Returns:\n",
    "      DataFrame: The transformed DataFrame\n",
    "    '''\n",
    "    # Convert a bunch of counting stats to be ratio's of plate appearences\n",
    "    counting_stats = ['R', 'H', '2B', '3B', 'HR', 'RBI', 'BB', 'IBB',\n",
    "                      'SO', 'HBP', 'SH', 'SF', 'GDP', 'SB', 'CS']\n",
    "    for counting_stat in counting_stats:\n",
    "        df[counting_stat] = df[counting_stat] / df['PA']\n",
    "    if min_PA is not None:\n",
    "        df = df[df.PA >= min_PA]\n",
    "    # Drop any columns with null's and a few non-numeric columns\n",
    "    return df.dropna().drop(columns=['#days', 'Lev', 'Tm', 'PA', 'G', 'AB'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_ranges = [ [ ['2012-07-01', '2015-06-30'], ['2015-07-01', '2015-09-30'], ['2016-04-01', '2016-06-30'] ],  \n",
    "              [ ['2013-04-01', '2015-09-30'], ['2016-04-01', '2016-06-30'], ['2016-07-01', '2016-09-30'] ],  \n",
    "              [ ['2013-07-01', '2016-06-30'], ['2016-07-01', '2016-09-30'], ['2017-04-01', '2017-06-30'] ], \n",
    "              [ ['2014-04-01', '2016-09-30'], ['2017-04-01', '2017-06-30'], ['2017-07-01', '2017-09-30'] ], \n",
    "              [ ['2014-07-01', '2017-06-30'], ['2017-07-01', '2017-09-30'], ['2018-04-01', '2018-06-30'] ],\n",
    "              [ ['2015-04-01', '2017-09-30'], ['2018-04-01', '2018-06-30'], ['2018-07-01', '2018-09-30'] ] ]\n",
    "dt_ranges = [ [ ['2010-04-01', '2010-09-30'], ['2011-04-01', '2011-06-30'] ],   \n",
    "              [ ['2010-07-01', '2011-06-30'], ['2011-07-01', '2011-09-30'] ],   \n",
    "              [ ['2011-04-01', '2011-09-30'], ['2012-04-01', '2012-06-30'] ],   \n",
    "              [ ['2011-07-01', '2012-06-30'], ['2012-07-01', '2012-09-30'] ],   \n",
    "              [ ['2012-04-01', '2012-09-30'], ['2013-04-01', '2013-06-30'] ],   \n",
    "              [ ['2012-07-01', '2013-06-30'], ['2013-07-01', '2013-09-30'] ],  \n",
    "              [ ['2013-04-01', '2013-09-30'], ['2014-04-01', '2014-06-30'] ],  \n",
    "              [ ['2013-07-01', '2014-06-30'], ['2014-07-01', '2014-09-30'] ],  \n",
    "              [ ['2014-04-01', '2014-09-30'], ['2015-04-01', '2015-06-30'] ],  \n",
    "              [ ['2014-07-01', '2015-06-30'], ['2015-07-01', '2015-09-30'] ], \n",
    "              [ ['2015-04-01', '2015-09-30'], ['2016-04-01', '2016-06-30'] ], \n",
    "              [ ['2015-07-01', '2016-06-30'], ['2016-07-01', '2016-09-30'] ], \n",
    "              [ ['2016-04-01', '2016-09-30'], ['2017-04-01', '2017-06-30'] ], \n",
    "              [ ['2016-07-01', '2017-06-30'], ['2017-07-01', '2017-09-30'] ], \n",
    "              [ ['2017-04-01', '2017-09-30'], ['2018-04-01', '2018-06-30'] ],\n",
    "              [ ['2017-07-01', '2018-06-30'], ['2018-07-01', '2018-09-30'] ] ]\n",
    "df = None\n",
    "for dt_range in dt_ranges:\n",
    "  if df is None:\n",
    "    df = build_hitting_dataset(dt_range, 'HR', min_PA=200)\n",
    "  else:\n",
    "    df = pd.concat([df, build_hitting_dataset(dt_range, 'HR', min_PA=200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2442 entries, 152 to 114\n",
      "Data columns (total 20 columns):\n",
      "Age_P0    2442 non-null int64\n",
      "R_P0      2442 non-null float64\n",
      "H_P0      2442 non-null float64\n",
      "2B_P0     2442 non-null float64\n",
      "3B_P0     2442 non-null float64\n",
      "HR_P0     2442 non-null float64\n",
      "RBI_P0    2442 non-null float64\n",
      "BB_P0     2442 non-null float64\n",
      "IBB_P0    2442 non-null float64\n",
      "SO_P0     2442 non-null float64\n",
      "HBP_P0    2442 non-null float64\n",
      "SH_P0     2442 non-null float64\n",
      "SF_P0     2442 non-null float64\n",
      "GDP_P0    2442 non-null float64\n",
      "SB_P0     2442 non-null float64\n",
      "CS_P0     2442 non-null float64\n",
      "BA_P0     2442 non-null float64\n",
      "OBP_P0    2442 non-null float64\n",
      "SLG_P0    2442 non-null float64\n",
      "OPS_P0    2442 non-null float64\n",
      "dtypes: float64(19), int64(1)\n",
      "memory usage: 400.6 KB\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data = train.iloc[:,1:-1]\n",
    "train_label = train.iloc[:,-1]\n",
    "test_data = test.iloc[:,1:-1]\n",
    "test_label = test.iloc[:,-1]\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2442.000000\n",
       "mean        0.030522\n",
       "std         0.016985\n",
       "min         0.000000\n",
       "25%         0.017498\n",
       "50%         0.029412\n",
       "75%         0.041667\n",
       "max         0.105556\n",
       "Name: HR, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46101612360014405"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LinearRegressionModel\n",
    "model = LinearRegression(normalize=False)\n",
    "model.fit(train_data, train_label)\n",
    "model.score(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression model\n",
    "model = linear_model.Lasso(alpha=0.1, normalize=False)\n",
    "model.fit(train_data, train_label)\n",
    "model.score(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ElasticNet regression model\n",
    "model = linear_model.ElasticNet()\n",
    "model.fit(train_data, train_label)\n",
    "model.score(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4435136815493899"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression\n",
    "model = linear_model.Ridge(alpha=.5)\n",
    "model.fit(train_data, train_label)\n",
    "model.score(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172637603095558"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(Normalizer(), PolynomialFeatures(2), LinearRegression(normalize=False))\n",
    "model.fit(train_data, train_label)\n",
    "model.score(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31351583830501295"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"../data/hr.model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
